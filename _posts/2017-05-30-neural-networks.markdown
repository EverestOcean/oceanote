---
layout: post
title:  "神经网络简单介绍"
date:   2017-05-30 09:00:00 +0800
categories: [deeplearning,machine-learning]
---

翻译至 [Understanding and coding Neural Networks From Scratch in Python and R](https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/)


<h2> 目录：</h2>

* [1. 神经网络简介](#1)
* [2. 多层感知机及其基本概念](#2)
* [3. 神经网络方法操作步骤](#3)
* [4. 可视化神经网络操作](#4)
* [5. Numpy 实现神经网络](#5)
* [6. 后向算法数学推理](#6)
* [7. 参考文献](#7)


<h3 id="1">1. 神经网络简介 </h3>

在我们调试代码寻找bug的时候，我们通常的做法是在不同的环境或者输入不同的输入数据，通过对不同结果的分析，从而判断出bug应该会在哪个模块或者某行代码中出现。当你找到了出错的地方，并作出修改后，我们还是会使用不同的输入进行不断的测试，直到确定代码的正确性。

同理神经网络的运行逻辑也与调试bug类似。输入不同的样本数据，通过不同隐藏层(hidden layer)下不同的神经元(neurons)的计算，最后通过输出层(output layer)计算出最终的结果。这种预测结果的方法通常被称作 **前向传播(Forward Propagation)**。

接下来，我们将前向传播预测的结果与实际结果进行比较，这个过程最终的目的是让预测的结果尽量逼近实际结果。在这个过程中，每个神经元对最终输出结果都带来了一定的误差，那么我们该怎么减少这类误差？

类似寻找bug一样，我们可以采用向后推导，从而找出哪个神经元出现了偏差，修正这些神经元的权重，降低它们的权重，这个过程通常被称为 **后向传播(Backward Propagation)**。

为了更好更快的降低结果的误差，并且减少前向和后向的迭代次数。神经网络采用了 **梯度下降(“Gradient Descent)** 优化算法。

这就是神经网络的工作原理。通过这种简单直观的描述，主要是为了让大家对神经网络有一个初级的认识。


<h3 id="2">2. 多层感知机及其基本概念</h3>

就像地球上的物质是由原子构成，神经网络的基本单元就是 **感知机(perceptron)**。那么什么是感知机？

感知机可以被认为是通过获取多个输入，通过某种计算，最终得到一个输出的处理单元，如图1所示：

![感知机(perceptron)](/static/img/_posts/neural-networks/perceptron.png)

通过上图可以看出，感知机获取三个输入，并最终输出一个结果。那么接下来的逻辑是，这三个输入与最终的输出结果之间是什么样的关系呢？让我们先从简单的逻辑开始，在此基础上再进一步引申出更复杂的逻辑。

下面，我们讨论了三种不同的输入输出关系：

1. **通过简单的组合逻辑将不同的输入组合在一起，并通过阈值计算出结果。** 例如： 假设 $$x_1=0, x_2=1, x_3=1$$ 并且同时设定阈值$$\theta=0$$。因此能够得到，如果$$x_1+x_2+x_3>0$$ 的输出结果为 $$1$$  否则结果为 $$0$$。你可以看到，在这个例子中感知机的输出结果为 $$1$$
2. **接下来，我们对输入增加些权限。** 权重给不同的输入赋予了不同的重要性。例如：将 $$x_1, x_2, x_3$$ 的权重分别设置为 $$w_1=2, w_2=3, w_3=4$$ 


<h3 id="7"> 7. 参考文献 </h3>

* [Understanding and coding Neural Networks From Scratch in Python and R](https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/)

