---
layout: post
title:  "TF-IDF 算法"
date:   2013-04-01 09:00:00 +0800
categories: [machine-learning, algorithm]
---


### TF-IDF 权重

在一个大文本语料中，存在一些对文档描述帮助比较少的词，例如: 英语中的 ‘is’， ‘and’等单词。这些单词在英文文档中经常出现，但是对于描述文档没有太大的作用。所以如果我们把这些词的统计信息直接放入文档分类器中，那么会使得一些有意义的词的统计信息在分类器中得不到很好的利用。

TF-IDF（term-frequency-inverse documnent frequency） 其中 TF意思是词频(Term Frequency)，IDF意思是逆文本频率指数(Inverse Document Frequency)， 是用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。同时也是一种信息检索与数据挖掘的常用的加权技术。所以，TF-IDF权重是某个词的TF权重，与IDF权重的乘积。

TF-IDF 的增加不仅跟该词在某一文档中出现的次数，同时还跟词在文件集合或者语料库中稀有性。

$$tf-idf(t, d, D)=tf(t, d) \times idf(t, D)$$

其中：

$$tf(t, d) = f(t, d)$$

$$idf(t, D) = log \frac{N}{\left|\{d \in D : t \in d\} \right|}$$

其中，$$f(t, d)$$ 指的是词 $$t$$ 在文档 $$d$$ 中出现的次数，我们将会使用该频率值作为词频 $$tf(t, d)$$。

$$N$$ 是文档集或语料库中包含的文档数，同时 $$|{d \in D: t \in d}|$$ 表示词 
$$t$$ 在多少文档中出现。


### 计算tf-idf

举个简单的例子，假设我们存在如下两个文档，对于不同词在不同文档出现的频次的统计表：

1. Documents1:  "It was many and many a year ago nn a kingdom by the sea"
2. Document 2: "I was a child and she was a child in this kingdom by the sea"

| | Document1 | Document2|
|:-:|:-:|:-:|
|It | 1 | 0 |
|i| 0| 1|
|was | 1 | 2|
|many|2 | 0|
|and | 1| 1|
|a | 2 | 2|
|year | 1| 0|
|ago | 1 | 0|
|In | 1 | 1|
|kingdom | 1 | 1 |
|by | 1| 1|
|the | 1 | 1|
|sea | 1 | 1|
|child | 0| 2|
|she | 0 | 1 | 
| this | 0 | 1 |

接下来，我们计算单词 文档1 中的'kingdom'的 tf-idf， 计算方法如下：

**tf**  从表中我们就可以直接的获取到，在该例子中对应的值为1。但是 **idf** 的计算就没那么直接了：

$$idf('kingdom', D) = log \frac{N}{\left|\{d \in D : t \in d\} \right|}$$

其中 $$N$$ 是文档集中包含的文档数，则值为2。‘kingdom’ 在两个文档中出现过，所以上式的值：

$$idf('kingdom', d) = log\frac{2}{2} = 0$$

那么 ‘kingdom’ 对应的 **tf-idf** 值为 0。

我们计算下“child” 对应的 tf-idf 值。 它只在一个文档中出现了两次。所以 tf-idf 的值为：

$$tf('child', d_{2}) = 2$$

$$idf('child', D) = log \frac{2}{1} = 0.3010$$

$$tf-idf('child', d_{2}, D) = tf('child', d_{2}) \times idf('child', D) = 2 \times log2 \approx 0.6 $$
